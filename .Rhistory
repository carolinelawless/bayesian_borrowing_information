# (6) importance weights (pre-resampling) for data_k
loglik <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[k]] <- w                 # STORE pre-resampling weights
# (7) resample if ESS low
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[k]] <- mu
}
return(list(mu_all = mu_all, w_all = w_all, epsilons = epsilons, V = V))
}
simulate_S <- function(params, n, M = 1e3, n_sim = 1e2, lambda = 1){ #n is a vector of length J
S_vals <- numeric(n_sim)
epsilons1 <- matrix(nrow = (length(params) - 1), ncol = n_sim)
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
result <- smc_sampler(V, M, lambda)
eps <- result$epsilons
S_vals[i] <- sum(eps)
epsilons1[,i] <- eps
#print(i)
}
epsilons2 <- apply(epsilons1, 1, mean)
return(list(S_vals, epsilons2))
}
simulate_S <- function(params, n, M, n_sim, lambda){ #n is a vector of length J
S_vals <- numeric(n_sim)
epsilons1 <- matrix(nrow = (length(params) - 1), ncol = n_sim)
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
result <- smc_sampler(V, M, lambda)
eps <- result$epsilons
S_vals[i] <- sum(eps)
epsilons1[,i] <- eps
#print(i)
}
epsilons2 <- apply(epsilons1, 1, mean)
return(list(S_vals, epsilons2))
}
remove(list = ls())
smc_sampler <- function(V, M, lambda) {
# V: list of length K
# M: number of particles
logsumexp <- function(x){
m <- max(x)
m + log(sum(exp(x - m)))
}
K <- length(V)
mu_all <- vector("list", K)   # store particle populations AFTER resampling (posterior approx)
w_all  <- vector("list", K)   # store pre-resampling normalized weights
epsilons <- numeric(K - 1)
# initial particles from prior Beta(1,1)
mu <- rbeta(M, a, b)
# ---- process dataset 1 ----
data1 <- V[[1]]
n1 <- length(data1)
s1 <- sum(data1)
loglik <- sapply(mu, function(m) sum(dbinom(data1, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[1]] <- w                 # STORE pre-resampling weights
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[1]] <- mu
# ---- loop k = 2..K ----
for (k in 2:K) {
data_k <- V[[k]]
n_k <- length(data_k)
s_k <- sum(data_k)
# (1) predictive under posterior (particles mu represent posterior after k-1)
loglik_post <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
log_pred <- logsumexp(loglik_post) - log(M)
# (2) baseline prior predictive
log_p0 <- lbeta(1 + s_k, 1 + n_k - s_k) - lbeta(1, 1)
# (3) epsilon
epsilon <- 1 / (1 + lambda*exp(log_p0 - log_pred))
epsilons[k - 1] <- epsilon
# (4) forgetting U
U <- rbinom(M, 1, epsilon)
# (5) refresh U==0 from posterior of data_k
idx_zero <- which(U == 0)
if (length(idx_zero) > 0) {
mu[idx_zero] <- rbeta(length(idx_zero), 1 + s_k, 1 + n_k - s_k)
}
# (6) importance weights (pre-resampling) for data_k
loglik <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[k]] <- w                 # STORE pre-resampling weights
# (7) resample if ESS low
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[k]] <- mu
}
return(list(mu_all = mu_all, w_all = w_all, epsilons = epsilons, V = V))
}
simulate_S <- function(params, n, M, nsim, lambda){ #n is a vector of length J
S_vals <- numeric(nsim)
epsilons1 <- matrix(nrow = (length(params) - 1), ncol = nsim)
J <- length(n)
for(i in 1:nsim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
result <- smc_sampler(V, M, lambda)
eps <- result$epsilons
S_vals[i] <- sum(eps)
epsilons1[,i] <- eps
#print(i)
}
epsilons2 <- apply(epsilons1, 1, mean)
return(list(S_vals, epsilons2))
}
lambda <- 1
M <- 250 #number of particles
a <- 10#beta prior
b <- 10 #beta prior
J <- 5 #number of versions
n <- rep(1e2, 5) #number of observations per version
nsim <- 1e3 #number of simulations for Monte Carlo S estimate
params_H0 <- rep(0.5, 5)
S_H0_all <- simulate_S(params_H0, n, M, nsim, lambda)
nsim <- 100
params_H0 <- rep(0.5, 5)
S_H0_all <- simulate_S(params_H0, n, M, nsim, lambda)
S_H0 <- S_H0_all[[1]]
epsilons_H0 <- S_H0_all[[2]]
threshold <- quantile(S_H0, 0.05)  # 5% quantile for 5% false positive rate
# Type 1 error
S_H0_all <- simulate_S(params_H0, n, M, nsim, lambda)
S_H0 <- S_H0_all[[1]]
type1_error <- length(which(S_H0 < threshold))/length(S_H0)
# Simulate under H1 (all params different)
params_H1_1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)  # all params different
S_H1_1_all <- simulate_S(params_H1_1, n, M, nsim, lambda)
S_H1_1 <- S_H1_1_all[[1]]
epsilons_H1_1 <- S_H1_1_all[[2]]
# epsilons_H1_1 #0.75, 0.68, 0.65, 0.64
# Check how often S_H1 < threshold to estimate power
power1 <- length(which(S_H1_1 < threshold))/length(S_H1_1) #0.491 #0.461 0.461
# Simulate under H1 (last param different)
params_H1_2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)  # last param different
S_H1_2_all <- simulate_S(params_H1_2, n, M, nsim, lambda)
S_H1_2 <- S_H1_2_all[[1]]
epsilons_H1_2 <- S_H1_2_all[[2]]
# epsilons_H1_2 #0.77, 0.78, 0.79, 0.23
# Check how often S_H1 < threshold to estimate power
power2 <- length(which(S_H1_2 < threshold))/length(S_H1_2) #0.76 0.723 0.71
print(paste0("n = ", paste(n, collapse = ", ")))
print(paste0("M =", M))
print(paste0("lambda =", lambda))
print(paste0("prior = Beta(",a, ",", b, ")"))
print(paste0("params H0 = ", paste(params_H0, collapse = ", ")))
print(paste0("params H1_1 = ", paste(params_H1_1, collapse = ", ")))
print(paste0("params H1_2 = ", paste(params_H1_2, collapse = ", ")))
print(paste0("threshold =",threshold))
print(paste0("type1 error =",type1_error))
print(paste0("power1 =",power1))
print(paste0("power2 =",power2))
print(paste0("mean_S_H0 =", mean(S_H0)))
print(paste0("sd_S_H0 =", sqrt(var(S_H0))))
print(paste0("mean_S_H1_1 =", mean(S_H1_1)))
print(paste0("sd_S_H1 =", sqrt(var(S_H1_1))))
print(paste0("mean_S_H1_2 =", mean(S_H1_2)))
print(paste0("sd_S_H2 =", sqrt(var(S_H1_2))))
round(mean(S_H0),2)
print(paste0("mean_S_H0 =", round(mean(S_H0), 2)),",", round(mean(S_H0), 2)), ",", round(mean(S_H0), 2))  )
print(paste0("mean_S_H0 =", round(mean(S_H0), 2),",", round(mean(S_H0), 2), ",", round(mean(S_H0), 2))  )
print(paste0("mean_S_H0 =", round(mean(S_H0), 2),",", round(mean(S_H1_1), 2), ",", round(mean(S_H1_2), 2))  )
print(paste0("sd_S =", round(sqrt(var(S_H0)), 2),",", round(sqrt(var(S_H1_1)), 2), ",", round(sqrt(var(S_H1_2)), 2)  )
print(paste0("sd_S =", round(sqrt(var(S_H0)), 2),",", round(sqrt(var(S_H1_1)), 2), ",", round(sqrt(var(S_H1_2)), 2)  ) )
print(paste0("sd_S =", round(sqrt(var(S_H0)), 2),",", round(sqrt(var(S_H1_1)), 2), ",", round(sqrt(var(S_H1_2)), 2)  ) )
print(paste0("mean_S =", round(mean(S_H0), 2),",", round(mean(S_H1_1), 2), ",", round(mean(S_H1_2), 2))  )
remove(list = ls())
smc_sampler <- function(V, M, lambda) {
# V: list of length K
# M: number of particles
logsumexp <- function(x){
m <- max(x)
m + log(sum(exp(x - m)))
}
K <- length(V)
mu_all <- vector("list", K)   # store particle populations AFTER resampling (posterior approx)
w_all  <- vector("list", K)   # store pre-resampling normalized weights
epsilons <- numeric(K - 1)
# initial particles from prior Beta(1,1)
mu <- rbeta(M, a, b)
# ---- process dataset 1 ----
data1 <- V[[1]]
n1 <- length(data1)
s1 <- sum(data1)
loglik <- sapply(mu, function(m) sum(dbinom(data1, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[1]] <- w                 # STORE pre-resampling weights
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[1]] <- mu
# ---- loop k = 2..K ----
for (k in 2:K) {
data_k <- V[[k]]
n_k <- length(data_k)
s_k <- sum(data_k)
# (1) predictive under posterior (particles mu represent posterior after k-1)
loglik_post <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
log_pred <- logsumexp(loglik_post) - log(M)
# (2) baseline prior predictive
log_p0 <- lbeta(1 + s_k, 1 + n_k - s_k) - lbeta(1, 1)
# (3) epsilon
epsilon <- 1 / (1 + lambda*exp(log_p0 - log_pred))
epsilons[k - 1] <- epsilon
# (4) forgetting U
U <- rbinom(M, 1, epsilon)
# (5) refresh U==0 from posterior of data_k
idx_zero <- which(U == 0)
if (length(idx_zero) > 0) {
mu[idx_zero] <- rbeta(length(idx_zero), 1 + s_k, 1 + n_k - s_k)
}
# (6) importance weights (pre-resampling) for data_k
loglik <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[k]] <- w                 # STORE pre-resampling weights
# (7) resample if ESS low
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[k]] <- mu
}
return(list(mu_all = mu_all, w_all = w_all, epsilons = epsilons, V = V))
}
simulate_S <- function(params, n, M, nsim, lambda){ #n is a vector of length J
S_vals <- numeric(nsim)
epsilons1 <- matrix(nrow = (length(params) - 1), ncol = nsim)
J <- length(n)
for(i in 1:nsim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
result <- smc_sampler(V, M, lambda)
eps <- result$epsilons
S_vals[i] <- sum(eps)
epsilons1[,i] <- eps
#print(i)
}
epsilons2 <- apply(epsilons1, 1, mean)
return(list(S_vals, epsilons2))
}
lambda <- 1
M <- 1000
a <- 10#beta prior
b <- 10 #beta prior
J <- 5 #number of versions
n <- rep(1e1, 5) #number of observations per version
nsim <- 100
params_H0 <- rep(0.5, 5)
S_H0_all <- simulate_S(params_H0, n, M, nsim, lambda)
S_H0 <- S_H0_all[[1]]
epsilons_H0 <- S_H0_all[[2]]
threshold <- quantile(S_H0, 0.05)  # 5% quantile for 5% false positive rate
# Type 1 error
S_H0_all <- simulate_S(params_H0, n, M, nsim, lambda)
S_H0 <- S_H0_all[[1]]
type1_error <- length(which(S_H0 < threshold))/length(S_H0)
# Simulate under H1 (all params different)
params_H1_1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)  # all params different
S_H1_1_all <- simulate_S(params_H1_1, n, M, nsim, lambda)
S_H1_1 <- S_H1_1_all[[1]]
epsilons_H1_1 <- S_H1_1_all[[2]]
# epsilons_H1_1 #0.75, 0.68, 0.65, 0.64
# Check how often S_H1 < threshold to estimate power
power1 <- length(which(S_H1_1 < threshold))/length(S_H1_1) #0.491 #0.461 0.461
# Simulate under H1 (last param different)
params_H1_2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)  # last param different
S_H1_2_all <- simulate_S(params_H1_2, n, M, nsim, lambda)
S_H1_2 <- S_H1_2_all[[1]]
epsilons_H1_2 <- S_H1_2_all[[2]]
# epsilons_H1_2 #0.77, 0.78, 0.79, 0.23
# Check how often S_H1 < threshold to estimate power
power2 <- length(which(S_H1_2 < threshold))/length(S_H1_2) #0.76 0.723 0.71
print(paste0("n = ", paste(n, collapse = ", ")))
print(paste0("M =", M))
print(paste0("lambda =", lambda))
print(paste0("prior = Beta(",a, ",", b, ")"))
print(paste0("params H0 = ", paste(params_H0, collapse = ", ")))
print(paste0("params H1_1 = ", paste(params_H1_1, collapse = ", ")))
print(paste0("params H1_2 = ", paste(params_H1_2, collapse = ", ")))
print(paste0("threshold =",threshold))
print(paste0("type1 error =",type1_error))
print(paste0("power1 =",power1))
print(paste0("power2 =",power2))
print(paste0("mean_S =", round(mean(S_H0), 2),",", round(mean(S_H1_1), 2), ",", round(mean(S_H1_2), 2))  )
print(paste0("sd_S =", round(sqrt(var(S_H0)), 2),",", round(sqrt(var(S_H1_1)), 2), ",", round(sqrt(var(S_H1_2)), 2)  ) )
n <- rep(20, 5)
lambda <- 3
params_H0 <- rep(0.5, 5)
S_H0_all <- simulate_S(params_H0, n, M, nsim, lambda)
S_H0 <- S_H0_all[[1]]
epsilons_H0 <- S_H0_all[[2]]
threshold <- quantile(S_H0, 0.05)  # 5% quantile for 5% false positive rate
# Type 1 error
S_H0_all <- simulate_S(params_H0, n, M, nsim, lambda)
S_H0 <- S_H0_all[[1]]
type1_error <- length(which(S_H0 < threshold))/length(S_H0)
# Simulate under H1 (all params different)
params_H1_1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)  # all params different
S_H1_1_all <- simulate_S(params_H1_1, n, M, nsim, lambda)
S_H1_1 <- S_H1_1_all[[1]]
epsilons_H1_1 <- S_H1_1_all[[2]]
# epsilons_H1_1 #0.75, 0.68, 0.65, 0.64
# Check how often S_H1 < threshold to estimate power
power1 <- length(which(S_H1_1 < threshold))/length(S_H1_1) #0.491 #0.461 0.461
# Simulate under H1 (last param different)
params_H1_2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)  # last param different
S_H1_2_all <- simulate_S(params_H1_2, n, M, nsim, lambda)
S_H1_2 <- S_H1_2_all[[1]]
epsilons_H1_2 <- S_H1_2_all[[2]]
# epsilons_H1_2 #0.77, 0.78, 0.79, 0.23
# Check how often S_H1 < threshold to estimate power
power2 <- length(which(S_H1_2 < threshold))/length(S_H1_2) #0.76 0.723 0.71
print(paste0("n = ", paste(n, collapse = ", ")))
print(paste0("M =", M))
print(paste0("lambda =", lambda))
print(paste0("prior = Beta(",a, ",", b, ")"))
print(paste0("params H0 = ", paste(params_H0, collapse = ", ")))
print(paste0("params H1_1 = ", paste(params_H1_1, collapse = ", ")))
print(paste0("params H1_2 = ", paste(params_H1_2, collapse = ", ")))
print(paste0("threshold =",threshold))
print(paste0("type1 error =",type1_error))
print(paste0("power1 =",power1))
print(paste0("power2 =",power2))
print(paste0("mean_S =", round(mean(S_H0), 2),",", round(mean(S_H1_1), 2), ",", round(mean(S_H1_2), 2))  )
print(paste0("sd_S =", round(sqrt(var(S_H0)), 2),",", round(sqrt(var(S_H1_1)), 2), ",", round(sqrt(var(S_H1_2)), 2)  ) )
# ##Posterior predictive
# ##Posterior predictive
# n <- 1e3
0.01/0.26
hist(rbeta(1e3, 100,100))
plot(density(rbeta(1e3, 100,100)))
rbinom(10,1, 0.5)
rbinom(10,1, 0.5)
plot(density(rbeta(1e3, 10,10)))
0.02/0.24
1e2
remove(list = ls())
setwd("/Users/clawless/Documents/MediTwin/bayesian_borrowing_information")
source("TEA_functions.R")
a <- 1
b <- 1
M <- 1000
lambda <- 1
J <- 5
n <- rep(1e1, J)
params0 <- rep(0.5, J)
params1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)
params2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)
npred <- 5e3
delta <- 0.2
V <- list()
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
J <- 5
n <- rep(2e1, J)
params0 <- rep(0.5, J)
params1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)
params2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
n <- rep(5e1, J)
params0 <- rep(0.5, J)
params1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)
params2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
params0 <- rep(0.5, J)
params1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)
params2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
n <- rep(1e2, J)
params0 <- rep(0.5, J)
params1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)
params2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
remove(list = ls())
setwd("/Users/clawless/Documents/MediTwin/bayesian_borrowing_information")
source("TEA_functions.R")
a <- 1
b <- 1
M <- 1000
lambda <- 1
J <- 5
n <- rep(1e2, J)
params0 <- rep(0.5, J)
params1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)
params2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
remove(list = ls())
setwd("/Users/clawless/Documents/MediTwin/bayesian_borrowing_information")
source("TEA_functions.R")
a <- 1
b <- 1
M <- 1000
lambda <- 1
J <- 5
n <- rep(1e2, J)
params0 <- rep(0.5, J)
params1 <- c(0.5, 0.6, 0.7, 0.8, 0.9)
params2 <- c(0.5, 0.5, 0.5, 0.5, 0.9)
npred <- 5e3
delta <- 0.2
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params0[j])
}
smc_out <- smc_sampler(V, M, lambda)
diffs <- posterior_predictive_diff(smc_out, npred)
gamma <- sum(abs(diffs) > delta)/length(diffs)
round(gamma, 2)
