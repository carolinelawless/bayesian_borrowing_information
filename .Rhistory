mu[idx_zero] <- rbeta(length(idx_zero), 1 + s_k, 1 + n_k - s_k)
}
# (6) importance weights (pre-resampling) for data_k
loglik <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[k]] <- w                 # STORE pre-resampling weights
# (7) resample if ESS low
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[k]] <- mu
}
return(list(mu_all = mu_all, w_all = w_all, epsilons = epsilons, V = V))
}
simulate_S <- function(params, n, M = 1e3, n_sim = 1e2){ #n is a vector of length J
S_vals <- numeric(n_sim)
epsilons1 <- matrix(nrow = (length(params) - 1), ncol = n_sim)
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
result <- smc_sampler(V, M)
eps <- result$epsilons
S_vals[i] <- sum(eps)
epsilons1[,i] <- eps
#print(i)
}
epsilons2 <- apply(epsilons1, 1, mean)
return(list(S_vals, epsilons2))
}
remove(list -= ls())
remove(list = ls())
smc_sampler <- function(V, M = 1e3) {
# V: list of length K
# M: number of particles
logsumexp <- function(x){
m <- max(x)
m + log(sum(exp(x - m)))
}
K <- length(V)
mu_all <- vector("list", K)   # store particle populations AFTER resampling (posterior approx)
w_all  <- vector("list", K)   # store pre-resampling normalized weights
epsilons <- numeric(K - 1)
# initial particles from prior Beta(1,1)
mu <- rbeta(M, 1, 1)
# ---- process dataset 1 ----
data1 <- V[[1]]
n1 <- length(data1)
s1 <- sum(data1)
loglik <- sapply(mu, function(m) sum(dbinom(data1, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[1]] <- w                 # STORE pre-resampling weights
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[1]] <- mu
# ---- loop k = 2..K ----
for (k in 2:K) {
data_k <- V[[k]]
n_k <- length(data_k)
s_k <- sum(data_k)
# (1) predictive under posterior (particles mu represent posterior after k-1)
loglik_post <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
log_pred <- logsumexp(loglik_post) - log(M)
# (2) baseline prior predictive
log_p0 <- lbeta(1 + s_k, 1 + n_k - s_k) - lbeta(1, 1)
# (3) epsilon
epsilon <- 1 / (1 + exp(log_p0 - log_pred))
epsilons[k - 1] <- epsilon
# (4) forgetting U
U <- rbinom(M, 1, epsilon)
# (5) refresh U==0 from posterior of data_k
idx_zero <- which(U == 0)
if (length(idx_zero) > 0) {
mu[idx_zero] <- rbeta(length(idx_zero), 1 + s_k, 1 + n_k - s_k)
}
# (6) importance weights (pre-resampling) for data_k
loglik <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[k]] <- w                 # STORE pre-resampling weights
# (7) resample if ESS low
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[k]] <- mu
}
return(list(mu_all = mu_all, w_all = w_all, epsilons = epsilons, V = V))
}
simulate_S <- function(params, n, M = 1e3, n_sim = 1e2){ #n is a vector of length J
S_vals <- numeric(n_sim)
epsilons1 <- matrix(nrow = (length(params) - 1), ncol = n_sim)
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
result <- smc_sampler(V, M)
eps <- result$epsilons
S_vals[i] <- sum(eps)
epsilons1[,i] <- eps
#print(i)
}
epsilons2 <- apply(epsilons1, 1, mean)
return(list(S_vals, epsilons2))
}
posterior_predictive_diff <- function(smc_out, n, n_pred = 2e3) {
# smc_out: output of smc_sampler(V, M)
# n: dataset size (number of observations per version row in V)
# n_pred: number of posterior predictive replicates
mu_all <- smc_out$mu_all
w_all  <- smc_out$w_all
K <- length(mu_all)
# posterior represented after dataset 1 is encoded in mu_all[[1]] (resampled),
# pre-resample weights for that step are w_all[[1]]
mu1 <- mu_all[[1]]
w1  <- w_all[[1]]
muK <- mu_all[[K]]
wK  <- w_all[[K]]
diffs <- numeric(n_pred)
for (b in 1:n_pred) {
# draw a particle index according to pre-resampling posterior weights
i1 <- sample.int(length(mu1), size = 1, prob = w1)
iK <- sample.int(length(muK), size = 1, prob = wK)
theta1 <- mu1[i1]
thetaK <- muK[iK]
y1_rep <- rbinom(n, 1, theta1)
yK_rep <- rbinom(n, 1, thetaK)
diffs[b] <- mean(yK_rep) - mean(y1_rep)  # e.g. current minus first
}
return(diffs)
}
params <- rep(0.5, 5)
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(v)
smc_out <- smc_sampler(V)
smc_out
post_pred <- posterior_predictive_diff(smc_out, n)
post_pred
mean(post_pred)
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
remove(list = ls())
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
smc_sampler <- function(V, M = 1e3) {
# V: list of length K
# M: number of particles
logsumexp <- function(x){
m <- max(x)
m + log(sum(exp(x - m)))
}
K <- length(V)
mu_all <- vector("list", K)   # store particle populations AFTER resampling (posterior approx)
w_all  <- vector("list", K)   # store pre-resampling normalized weights
epsilons <- numeric(K - 1)
# initial particles from prior Beta(1,1)
mu <- rbeta(M, 1, 1)
# ---- process dataset 1 ----
data1 <- V[[1]]
n1 <- length(data1)
s1 <- sum(data1)
loglik <- sapply(mu, function(m) sum(dbinom(data1, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[1]] <- w                 # STORE pre-resampling weights
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[1]] <- mu
# ---- loop k = 2..K ----
for (k in 2:K) {
data_k <- V[[k]]
n_k <- length(data_k)
s_k <- sum(data_k)
# (1) predictive under posterior (particles mu represent posterior after k-1)
loglik_post <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
log_pred <- logsumexp(loglik_post) - log(M)
# (2) baseline prior predictive
log_p0 <- lbeta(1 + s_k, 1 + n_k - s_k) - lbeta(1, 1)
# (3) epsilon
epsilon <- 1 / (1 + exp(log_p0 - log_pred))
epsilons[k - 1] <- epsilon
# (4) forgetting U
U <- rbinom(M, 1, epsilon)
# (5) refresh U==0 from posterior of data_k
idx_zero <- which(U == 0)
if (length(idx_zero) > 0) {
mu[idx_zero] <- rbeta(length(idx_zero), 1 + s_k, 1 + n_k - s_k)
}
# (6) importance weights (pre-resampling) for data_k
loglik <- sapply(mu, function(m) sum(dbinom(data_k, 1, m, log = TRUE)))
maxll <- max(loglik)
w <- exp(loglik - maxll)
w <- w / sum(w)
w_all[[k]] <- w                 # STORE pre-resampling weights
# (7) resample if ESS low
ESS <- 1 / sum(w^2)
if (ESS < M/2){
mu <- mu[sample.int(M, M, replace = TRUE, prob = w)]
}
mu_all[[k]] <- mu
}
return(list(mu_all = mu_all, w_all = w_all, epsilons = epsilons, V = V))
}
simulate_S <- function(params, n, M = 1e3, n_sim = 1e2){ #n is a vector of length J
S_vals <- numeric(n_sim)
epsilons1 <- matrix(nrow = (length(params) - 1), ncol = n_sim)
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
result <- smc_sampler(V, M)
eps <- result$epsilons
S_vals[i] <- sum(eps)
epsilons1[,i] <- eps
#print(i)
}
epsilons2 <- apply(epsilons1, 1, mean)
return(list(S_vals, epsilons2))
}
posterior_predictive_diff <- function(smc_out, n, n_pred = 2e3) {
# smc_out: output of smc_sampler(V, M)
# n: dataset size (number of observations per version row in V)
# n_pred: number of posterior predictive replicates
mu_all <- smc_out$mu_all
w_all  <- smc_out$w_all
K <- length(mu_all)
# posterior represented after dataset 1 is encoded in mu_all[[1]] (resampled),
# pre-resample weights for that step are w_all[[1]]
mu1 <- mu_all[[1]]
w1  <- w_all[[1]]
muK <- mu_all[[K]]
wK  <- w_all[[K]]
diffs <- numeric(n_pred)
for (b in 1:n_pred) {
# draw a particle index according to pre-resampling posterior weights
i1 <- sample.int(length(mu1), size = 1, prob = w1)
iK <- sample.int(length(muK), size = 1, prob = wK)
theta1 <- mu1[i1]
thetaK <- muK[iK]
y1_rep <- rbinom(n, 1, theta1)
yK_rep <- rbinom(n, 1, thetaK)
diffs[b] <- mean(yK_rep) - mean(y1_rep)  # e.g. current minus first
}
return(diffs)
}
params <- rep(0.5, 5)
n <- c(10, 20, 30, 100, 20)
M <- 1e3
n_sim <- 1e2
J <- length(n)
for(i in 1:n_sim){
V <- list()
for(j in 1:J){
V[[j]] <- rbinom(n[j], 1, params[j])
}
}
smc_out <- smc_sampler(V)
post_pred <- posterior_predictive_diff(smc_out, n)
mean(post_pred)
n_sim
nsim = n_sim
S_H0_all <- simulate_S(rep(0.5, 5), n, n_sim = nsim)
S_H0 <- S_H0_all[[1]]
epsilons_H0 <- S_H0_all[[2]]
threshold <- quantile(S_H0, 0.05)  # 5% quantile for 5% false positive rate
threshold
n
# Simulate under H1 (all params different)
params_H1_1 <- c(0.5, 0.55, 0.6, 0.65, 0.7)  # all params different
S_H1_1_all <- simulate_S(params_H1_1, n, n_sim = nsim)
S_H1_1 <- S_H1_1_all[[1]]
epsilons_H1_1 <- S_H1_1_all[[2]]
# epsilons_H1_1 #0.75, 0.68, 0.65, 0.64
# Check how often S_H1 < threshold to estimate power
power1 <- length(which(S_H1_1 < threshold))/length(S_H1_1) #0.491 #0.461 0.461
print("test4")
# Simulate under H1 (last param different)
params_H1_2 <- c(0.5, 0.5, 0.5, 0.5, 0.7)  # last param different
S_H1_2_all <- simulate_S(params_H1_2, n, n_sim = nsim)
S_H1_2 <- S_H1_2_all[[1]]
epsilons_H1_2 <- S_H1_2_all[[2]]
# epsilons_H1_2 #0.77, 0.78, 0.79, 0.23
# Check how often S_H1 < threshold to estimate power
power2 <- length(which(S_H1_2 < threshold))/length(S_H1_2) #0.76 0.723 0.71
power1
power2
n
n <- rep(1e2, 5)
nsim <- 1e3
S_H0_all <- simulate_S(rep(0.5, 5), n, n_sim = nsim)
S_H0 <- S_H0_all[[1]]
epsilons_H0 <- S_H0_all[[2]]
threshold <- quantile(S_H0, 0.05)  # 5% quantile for 5% false positive rate
print(threshold)
print("test3")
# Simulate under H1 (all params different)
params_H1_1 <- c(0.5, 0.55, 0.6, 0.65, 0.7)  # all params different
S_H1_1_all <- simulate_S(params_H1_1, n, n_sim = nsim)
threshold
p1
power1
nsim
nsim <- 1e2
n
S_H0_all <- simulate_S(rep(0.5, 5), n, n_sim = nsim)
S_H0 <- S_H0_all[[1]]
epsilons_H0 <- S_H0_all[[2]]
threshold <- quantile(S_H0, 0.05)  # 5% quantile for 5% false positive rate
print(threshold)
print("test3")
# Simulate under H1 (all params different)
params_H1_1 <- c(0.5, 0.55, 0.6, 0.65, 0.7)  # all params different
S_H1_1_all <- simulate_S(params_H1_1, n, n_sim = nsim)
S_H1_1 <- S_H1_1_all[[1]]
epsilons_H1_1 <- S_H1_1_all[[2]]
# epsilons_H1_1 #0.75, 0.68, 0.65, 0.64
# Check how often S_H1 < threshold to estimate power
power1 <- length(which(S_H1_1 < threshold))/length(S_H1_1) #0.491 #0.461 0.461
print("test4")
# Simulate under H1 (last param different)
params_H1_2 <- c(0.5, 0.5, 0.5, 0.5, 0.7)  # last param different
S_H1_2_all <- simulate_S(params_H1_2, n, n_sim = nsim)
S_H1_2 <- S_H1_2_all[[1]]
epsilons_H1_2 <- S_H1_2_all[[2]]
# epsilons_H1_2 #0.77, 0.78, 0.79, 0.23
# Check how often S_H1 < threshold to estimate power
power2 <- length(which(S_H1_2 < threshold))/length(S_H1_2) #0.76 0.723 0.71
print("test5")
print(power1)
print(power2)
params
remove(list = ls())
source("TEA_functions.R")
setwd("/Users/clawless/Documents/MediTwin/bayesian_borrowing_information")
source("TEA_functions.R")
J <- 5 #number of versions
n <- rep(1e2, 5) #number of observations per version
nsim <- rep(1e1, 5)
nsim
nsim <- 1e2
n <- rep(1e2, 5) #number of observations per version
params_H0 <- rep(0.5, 5)
S_H0_all <- simulate_S(params_H0, n, n_sim = nsim)
S_H0 <- S_H0_all[[1]]
epsilons_H0 <- S_H0_all[[2]]
threshold <- quantile(S_H0, 0.05)  # 5% quantile for 5% false positive rate
# Type 1 error
S_H0_all <- simulate_S(params_H0, n, n_sim = nsim)
S_H0 <- S_H0_all[[1]]
type1_error <- length(which(S_H0 < threshold))/length(S_H0)
# Simulate under H1 (all params different)
params_H1_1 <- c(0.5, 0.55, 0.6, 0.65, 0.7)  # all params different
S_H1_1_all <- simulate_S(params_H1_1, n, n_sim = nsim)
S_H1_1 <- S_H1_1_all[[1]]
epsilons_H1_1 <- S_H1_1_all[[2]]
# epsilons_H1_1 #0.75, 0.68, 0.65, 0.64
# Check how often S_H1 < threshold to estimate power
power1 <- length(which(S_H1_1 < threshold))/length(S_H1_1) #0.491 #0.461 0.461
# Simulate under H1 (last param different)
params_H1_2 <- c(0.5, 0.5, 0.5, 0.5, 0.7)  # last param different
S_H1_2_all <- simulate_S(params_H1_2, n, n_sim = nsim)
S_H1_2 <- S_H1_2_all[[1]]
epsilons_H1_2 <- S_H1_2_all[[2]]
# epsilons_H1_2 #0.77, 0.78, 0.79, 0.23
# Check how often S_H1 < threshold to estimate power
power2 <- length(which(S_H1_2 < threshold))/length(S_H1_2) #0.76 0.723 0.71
print(paste0("n =",n))
print(paste0("params H0 =",params_H0))
print(paste0("params H1_1 =",params_H1_1))
print(paste0("params H1_2 =",params_H1_2))
params_H1_2print(paste0("threshold =",threshold))
print(paste0("n =",n))
n
n <- 1:5
print(paste0("n =",n))
print(paste0("params H0 =",params_H0))
print(paste0("params H1_1 =",params_H1_1))
print(paste0("params H1_2 =",params_H1_2))
print(paste0("threshold =",threshold))
print(paste0("type1 error =",type1_error))
print(paste0("power1 =",power1))
print(paste0("power2 =",power2))
print(paste0("n = ", paste(n, collapse = ", ")))
print(paste0("params H0 = ", paste(params_H0, collapse = ", ")))
print(paste0("params H1_1 = ", paste(params_H1_1, collapse = ", ")))
print(paste0("params H1_2 = ", paste(params_H1_2, collapse = ", ")))
print(paste0("threshold =",threshold))
print(paste0("type1 error =",type1_error))
print(paste0("power1 =",power1))
print(paste0("power2 =",power2))
1e1
